\section{Introduction}

Being a huge fan of Matt and of Numperphile,
I recently watched the video \url{https://www.youtube.com/watch?v=q6L06pyt9CA},
featuring Matt Parker.  Despite Matt's infallibility, I decided to have my own
crack at the problem, in the spirit of mathematical enquiry and whatnot.

I reasoned that checking if a number is polygonal should be a roughly
\(\BigO(1)\) operation as we can find the \(n\)th term of the base-\(s\)
polygonal numbers \(P(s, n)\), which will be quadratic in \(n\), and solve it
for \(n\) with the quadratic formula, so to check if some cannonball numbers
\(C(s, n_c)\) is polygonal we just see if the corresponding \(n_p\) is an
integer. Now \(10^9\) is a fairly small number. Seeing as my CPU's clockspeed is
in the range of gigahertz, and we're just checking a tiny fraction of those
numbers as we're just computing the cannonball numbers under this limit, it
seems reasonable that this should be doable fairly fast.

I've thought about the problem of higher-dimensional stacks of cannonballs (ie
the ones formed by adding up the cannonball numbers), but I've not done anything
about it.

While I'm here I'd also like to plug square triangular numbers:
\url{https://en.wikipedia.org/wiki/Square_triangular_number}. I conjecture that
these are one of the least talked about, but coolest things in maths. For some
inexplicable reason (``````Pell's Equation''''''), if you take a convergent
\(b / c\) of \(\sqrt 2\), then \(b^2 c^2\) will be a square triangular number.
(Matt Parker voice) How cool is that?!

\section{State of the Union}

Below is presented a table of depths of \(s\) to which I've searched for various
upper bounds on \(C\). I did this mostly with one monumental overnight
computation on a fairly standard issue desktop computer (I can't bear to hear my
laptop's fan). Unfortunately I forgot to store the upper bound for each
computation, so they're just the largest number that's been found at that depth.
A couple of these may be an underestimate by about an order of magnitude.

\begin{longtable}{lr}
\toprule
\boldmath \(C(s, n) <\) & \boldmath \(s <\) \\
\midrule
\input{../src/depthtable}
\endhead
\bottomrule
\end{longtable}

I've also separately run some computation on numbers congruent to 2 module 3, as
I'll discuss more later. With these, I've checked polygons up the the gargantuan
\input{../src/2mod3count}.

\section{The Maths}

Indeed, this approach does seem to work. Almost by definition we have the
recurrence in polygonal numbers
\begin{equation*}
P(s, n) = P(s, n - 1) + n(s - 2) - (s - 3)
\end{equation*}
so we can use
\begin{align*}
P(s, n) &= \sum_{r = 1}^n P(s, r) - P(s, r - 1) \\
    &= \sum_{r = 1}^n (n(s - 2) - (s - 3)) \\
    &= \frac 12 n(n + 1)(s - 2) - n(s - 3) \\
    &= \frac{n^2(s - 2) - n(s - 4)} 2
\end{align*}
Fortunately this seems to agree with what Wikipedia thinks. Now, we have
\begin{alignat*}{2}
&& 0 &= (s - 2)n^2 - (s - 4)n - 2P(s, n) \\
&\implies& n &= \frac{s - 4 + \sqrt{(s - 4)^2 + 8(s - 2)P(s, n)}}{2s - 4}
\end{alignat*}
Wikipedia still seems to think we're on track.

Another result that I don't really use is that
\begin{align*}
C(s, n) &= \sum_{r = 1}^n P(s, n) \\
    &= \frac 12 \sum_{r = 1}^n (n^2(s - 2) - n(s - 4)) \\
    &= \frac 12 \pqty{\frac{n(n + 1)(2n + 1)(s - 2)} 6
                    - \frac{n(n + 1)(s - 4)} 2} \\
    &= \frac 1{12}n(n + 1)\bqty{(2n + 1)(s - 2) - 3(s - 4)}
\end{align*}
In fact I've only used this in verification of the results.

Regardless, now we need only work our way up the \(C(s, n)\)s using the
recurrence \(C(s, n) = P(s, n) + C(s, n - 1)\), and check for each if the
quadratic formula gives an integer result. This is most easily done by checking
if the discriminant is a perfect square and then checking that the denominator
divides the numerator.

\section{The Programming}

For speeeeeeed I implemented this in C (although there is a long abandoned
parallel Python implementation). I used 128-bit integers to be on the safe side,
as \(10^{19}\) is a little small for my liking. This meant I had to do a lot of
messing around to get things to actually display in base 10. This program is
shown in Listing \ref{lst_c}.

Of course, an isolated source code listing is both not executable and not
necessarily helpful, but fret not as my intact source tree is in
\texttt{../src}.

I did briefly consider either implementing or importing some kind of arbitrary
precision integer arithmetic functionality, but then I decided I wasn't going to
run it on anything fast enough to have to worry about that, and I have better
things to do.

There's also a slick little progress update that gets printed to STDERR. I've
written a number of interacting zsh scripts and Python scripts here and there to
manage the actual programs, forming a sort of terribly managed little pipeline,
with files that don't make any sense all over the place. Much of it is probably
also dependent on software that happens to be on my computer, like some Linux
coreutils. Obviously the C code will probably require GCC to work out of the
box.

I also have a program that verifies results, removes duplicates and formats them
into a \LaTeX{} table (spoilers for table \ref{tab_ugly}), shown in listing
\ref{lst_py_verif}.

After having used these programs to obtain some data, and plot it and so on and
so forth as discussed in the next section, I noticed the glaring pattern with
the cannonball numbers derived from a side congruent to 2 modulo 3. By
assuming that this pattern continues, in that you can move 3 along and a little
up to get to a new cannonball polygonal number, it is easy to generate these
kinds of numbers at a preposterous rate. I wrote a little C program (listing
\ref{lst_c_2mod3} which took maybe ten minutes to hit the upper bounds of
128-bit integer arithmetic, getting me to around 80000.

I then wrote a Python program (listing \ref{lst_py_2mod3}), which was at first
just a straightforward translation, to take advantage of Python's arbitrary
precision integers. I then decided I could probably take further advantage of
the curve, because really going up in linear steps felt a bit slow. I assumed
that the graph of \(s\) against \(n_C\) would be convex, such that each gap
between numbers is greater than the last. By making this assumption, I suddenly
started generating tens of thousands of solutions per second, getting to the
point where IO is the main bottleneck.

\begin{longlisting}
\inputminted{c}{../src/c/cannonball.c}
\caption{The main C source code}
\label{lst_c}
\end{longlisting}

\begin{longlisting}
\inputminted{python}{../src/factcheck.py}
\caption{Python verification program}
\label{lst_py_verif}
\end{longlisting}

\begin{longlisting}
\inputminted{c}{../src/c/2mod3/2mod3.c}
\caption{C program to find cannonball polygons for side congruent to 2 mod 3}
\label{lst_c_2mod3}
\end{longlisting}

\begin{longlisting}
\inputminted{python}{../src/c/2mod3/2mod3.py}
\caption{Python program like (\ref{lst_c_2mod3}) but cleverer.}
\label{lst_py_2mod3}
\end{longlisting}

\section{The Ugly}

I have plotted both the data in its entirety on a double logarithmic scale
\ref{fig_log_all}. The graphs started becoming so large after I came up with the
trick to generate 2-mod-3 numbers that I had to rasterise them. You can modify
the R code to make them be PDFs if you want but it will be slow.

The obvious pattern that jumps out is the big line of points for all the sides
congruent to \(2 \pmod 3\). Particularly because it looks like such a straight
line on the log-log plot, we would expect it to be modelled well as a constant
multiple of some power of \(s\). I drew two lines that seemed to roughly bound
it, and used those to extract the points on the line and then do some linear
regression on that (figure \ref{fig_log_boring}). I obtained the formula
\input{../graph/model}
This would seem to imply to me that it's probably a seventh-degree polynomial.

I wrote this paragraph, but not for a very long time did I think to actually
check. I first wasted a lot of time trying to brute force more points on the
line. When I did decide to check, I wrote the little Python program in listing
\ref{lst_sympy}, using the library Sympy to do a little linear algebra. I had a
sample of points from the line, from which I sampled randomly as a poor
approximation to checking if the fit works for all points. However, much to my
surprise, the program did consistently output the same coefficients, indicating
that the general formula for \(C\) where \(s \equiv 2 \pmod 3\) is (probably)
% Matrix([[1/162], [-7/81], [11/27], [-91/162], [-133/162], [103/54], [35/81], [-19/81]])
\begin{equation*}
C = \frac{1}{162}s^7 - \frac{7}{81}s^6 + \frac{11}{27}s^5 - \frac{91}{162}s^4
    - \frac{133}{162}s^3 + \frac{103}{54}s^2 + \frac{35}{81}s - \frac{19}{81}
\end{equation*}
Any reason why this could be true is waaaaaay over my head, although maybe it
has something to do with powers of 3.

I used this expression to calculate a really big number just for the hell of it.
I wrote a little code (as seen in listing \ref{lst_infinity}) to take some
integer \(i_n\), calculate \(s_n = 3i_n + 2\) and \(C_n\) from there. Now I made
repeatedly square \(i_n\) to advance - ie \(i_{n + 1} = i_n^2\) - just to
quickly get very big numbers. In fact I found that almost all of the hard bit is
calculating base-10 representations and typesetting them. \LaTeX{} very quickly
crashes with the biggest numbers I found (see
\texttt{../infinity\_and\_beyond/solutions/}), so I settled on a smaller one.
I used a sequence of \(9\) just because I wanted to use \(10\)s, but they end up
looking really artificial, because when you have a polynomial in a power of 10
you get odd artifacts in base 10.

\begin{longlisting}
\inputminted{python}{../investigate/solve.py}
\caption{Trying to find a polynomial}
\label{lst_sympy}
\end{longlisting}

\begin{longlisting}
\inputminted{python}{../infinity_and_beyond/buzz.py}
\caption{Calculating big numbers because I can}
\label{lst_infinity}
\end{longlisting}

I have also plotted these points on a linear scale, demonstrating their
relationship \ref{fig_linear_boring}.

Lastly, I plotted all points other than the points along this line in figure
\ref{fig_log_interesting}.

The R code I used to achieve all this is in Listing \ref{lst_R}.

Table \ref{tab_ugly} lists some solutions that I've found, so far. The \TeX{}
source of the table is in \texttt{../graph/interesting.tsv}, which is derived
from \texttt{../src/c/solutions/*}.  I have deliberately omitted the ``boring''
solutions along the dense line, favouring the more flavourful, stylish and
individualistic solutions.

There are also two tables \texttt{boring.tsv} and \texttt{all.tsv} containing
only the boring solutions and all solutions, respectively, but there are such a
truly mind-boggling number of boring solutions that really it's hardly any fun
looking at them.

Unfortunately at this point they're so big that I've had to arbitraryily curtail
them to 10000 lines, presented in \texttt{all\_extract.tsv}. The full length of
\texttt{all.tsv} is currently \input{../graph/all_linecount.tex}.

The rate of generation of these solutions is several orders of
magnitude above anything else, which does mean that you should be able to
generate your own set of a couple hundred million fairly quickly.

I have presented an extract of the full data set in the document
\texttt{biglist.pdf}.

\begin{longlisting}
\inputminted{R}{../graph/graph.R}
\caption{R graphical analysis}
\label{lst_R}
\end{longlisting}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{../graph/all_log.png}
\caption{Log plot}
\label{fig_log_all}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{../graph/boring_lin.png}
\caption{Linear plot of boring points}
\label{fig_linear_boring}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{../graph/boring_log.png}
\caption{Log plot of the boring points}
\label{fig_log_boring}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{../graph/interesting_log.png}
\caption{Log plot of the remaining points}
\label{fig_log_interesting}
\end{figure}

\begin{longtable}{*4r}
\toprule
\boldmath \(s\) & \boldmath \(C(s, n_c) = P(s, n_p)\)
& \boldmath \(n_p\) & \boldmath \(n_c\) \\
\midrule
\endhead
\input{../src/interesting}
\bottomrule
\caption{Polygonal Cannonball Numbers}
\label{tab_ugly}
\end{longtable}
